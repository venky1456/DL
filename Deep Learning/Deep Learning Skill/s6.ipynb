{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Preprocessing:\n",
        "\n",
        "The Iris dataset is loaded and filtered to include only two classes, turning it into a binary classification problem. The data is then standardized.\n",
        "Model Configurations:\n",
        "\n",
        "We define the SimpleNN class that allows flexible configuration of the network's hidden layers. It takes a list hidden_layers as input, which defines the number of neurons in each hidden layer.\n",
        "Training and Evaluation Function:\n",
        "\n",
        "The train_and_evaluate function initializes a model with the specified hidden layers, trains it using mini-batch gradient descent, and evaluates its accuracy on the test set.\n",
        "Configurations Comparison:\n",
        "\n",
        "We specify different configurations of hidden layers and compare them. Each configuration is described by the number of neurons in its hidden layers.\n",
        "Observations:\n",
        "By running this code, we can observe how different network architectures (depth and width) affect the model's performance on the binary classification task. Typically, deeper and wider networks can capture more complex patterns but may also require more data and computational power to train effectively. However, for simple datasets like the Iris dataset, simpler models may suffice and even outperform more complex ones due to their lower risk of overfitting."
      ],
      "metadata": {
        "id": "fvOmAx8sJxy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Compare the configurations a 2-class classification neural network to solve the use case\n",
        "\n",
        "\n",
        "To compare different configurations of a 2-class classification neural network, we'll implement several models with varying architectures and hyperparameters using the PyTorch framework. We'll use the Iris dataset for simplicity, focusing on two classes to create a binary classification problem.\n",
        "\n",
        "Setup and Data Preparation\n",
        "First, we'll load and preprocess the dataset. The Iris dataset will be filtered to include only two classes.\n",
        "\n",
        "Configurations to Compare\n",
        "Simple Network:\n",
        "\n",
        "1 hidden layer with 4 neurons.\n",
        "Deeper Network:\n",
        "\n",
        "2 hidden layers with 8 neurons each.\n",
        "Wider Network:\n",
        "\n",
        "1 hidden layer with 16 neurons.\n",
        "More Neurons:\n",
        "\n",
        "1 hidden layer with 32 neurons."
      ],
      "metadata": {
        "id": "uWePA07TJRJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load the Iris dataset and filter for binary classification (class 0 and 1)\n",
        "iris = load_iris()\n",
        "X = iris.data[iris.target != 2]\n",
        "y = iris.target[iris.target != 2]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# DataLoader for mini-batch training\n",
        "batch_size = 16\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Model configurations\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, hidden_layers):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        layers = []\n",
        "        input_dim = 4\n",
        "        for hidden_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            input_dim = hidden_dim\n",
        "        layers.append(nn.Linear(input_dim, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate(hidden_layers):\n",
        "    model = SimpleNN(hidden_layers)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    num_epochs = 100\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        predictions = (test_outputs > 0.5).float()\n",
        "        accuracy = (predictions == y_test_tensor).float().mean().item()\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Compare different configurations\n",
        "configurations = [\n",
        "    ([4], \"1 hidden layer with 4 neurons\"),\n",
        "    ([8, 8], \"2 hidden layers with 8 neurons each\"),\n",
        "    ([16], \"1 hidden layer with 16 neurons\"),\n",
        "    ([32], \"1 hidden layer with 32 neurons\")\n",
        "]\n",
        "\n",
        "for hidden_layers, description in configurations:\n",
        "    accuracy = train_and_evaluate(hidden_layers)\n",
        "    print(f\"Configuration: {description}, Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37aeccXSJXLY",
        "outputId": "ff0e9792-54b4-4db5-ec89-141e75def16f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration: 1 hidden layer with 4 neurons, Test Accuracy: 1.0000\n",
            "Configuration: 2 hidden layers with 8 neurons each, Test Accuracy: 1.0000\n",
            "Configuration: 1 hidden layer with 16 neurons, Test Accuracy: 1.0000\n",
            "Configuration: 1 hidden layer with 32 neurons, Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toacInvUJDh0"
      },
      "outputs": [],
      "source": []
    }
  ]
}